spring:
  application:
    name: order-core
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:orderdb} # Added DB_PORT and default DB_NAME
    username: ${DB_USER:order_user} # Added default user
    password: ${DB_PASS:order_pass} # Added default pass
    driver-class-name: org.postgresql.Driver # Good practice to specify driver
  jpa:
    hibernate:
      ddl-auto: validate # Use 'validate' with Flyway, 'none' is also common
    show-sql: false # Set to true for debugging, false for production/test
    properties:
      hibernate.format_sql: true
      hibernate.jdbc.lob.non_contextual_creation: true # For JsonType with older Hibernate versions if needed

flyway:
  enabled: true
  locations: classpath:db/migration # Default location, good to be explicit

keycloak:
  realm: MyRealm
  auth-server-url: ${KEYCLOAK_URL:http://localhost:8180/auth} # Default Keycloak URL
  resource: order-core-client # Client ID for Order-Core
  credentials:
    secret: ${KEYCLOAK_SECRET:your-order-core-client-secret} # Default secret, use env var
  bearer-only: true
  # public-client: false # Not a public client

kafka:
  bootstrap-servers: ${KAFKA_BROKER:localhost:9092}
  schema-registry-url: ${SCHEMA_REGISTRY_URL:http://localhost:8081} # For Avro
  consumer:
    group-id: order-core-group
    auto-offset-reset: earliest
    properties:
      # specific.avro.reader: true # To be enabled when Avro deserializer is used
      # For JsonDeserializer, if type information is embedded by producer:
      # spring.json.use.type.headers: false
      # spring.json.trusted.packages: "*"
      # These are configured in KafkaConsumerConfig programmatically, but can be here too.
      # Default Spring Kafka JsonDeserializer properties:
      spring.json.value.default.type: com.fasterxml.jackson.databind.JsonNode # Default for JsonNode consumers
      spring.json.trusted.packages: "*" # Trust all packages for JSON deserialization
  producer:
    key-serializer: org.apache.kafka.common.serialization.StringSerializer
    # Value serializer will be initially JsonSerializer, then switched to KafkaAvroSerializer
    value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    properties:
      # schema.registry.url: ${kafka.schema-registry-url} # To be enabled for Avro
      # acks: all # Configured in KafkaProducerConfig programmatically
      # retries: 3 # Configured in KafkaProducerConfig programmatically
      # retry.backoff.ms: 1000 # Configured in KafkaProducerConfig programmatically
      # For JsonSerializer, if producing type headers:
      spring.json.add.type.headers: false # If consumers don't rely on type headers or use specific JsonNode types
  topics:
    # Topics produced by Order-Core (via Outbox)
    orderCreated: ${ORDER_CORE_TOPIC_ORDER_CREATED:order.core.created}
    orderCancelled: ${ORDER_CORE_TOPIC_ORDER_CANCELLED:order.core.cancelled}
    orderStatusUpdatedPrefix: ${ORDER_CORE_TOPIC_STATUS_PREFIX:order.core.status}

    # Topics consumed by Order-Core for Saga progression
    inventoryReservationSucceeded: ${CONSUMED_TOPIC_RESERVATION_SUCCEEDED:inventory.reservation.succeeded}
    inventoryReservationFailed: ${CONSUMED_TOPIC_RESERVATION_FAILED:inventory.reservation.failed}
    paymentSucceeded: ${CONSUMED_TOPIC_PAYMENT_SUCCEEDED:payment.payment.succeeded}
    paymentFailed: ${CONSUMED_TOPIC_PAYMENT_FAILED:payment.payment.failed}
    # orderApiCreated: ${CONSUMED_TOPIC_ORDERAPI_CREATED:order.api.created} # Example if consuming from Order-API

app:
  outbox:
    poll-delay-ms: ${APP_OUTBOX_POLL_DELAY_MS:2000}
    initial-delay-ms: ${APP_OUTBOX_INITIAL_DELAY_MS:5000}

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,flyway # Expose Flyway endpoint too
  endpoint:
    health:
      show-details: when_authorized # Or 'always' if appropriate for your env
      probes:
        enabled: true # Enable k8s specific health probes for /health/readiness and /health/liveness

logging:
  level:
    com.mysillydreams.ordercore: INFO
    org.springframework.kafka: INFO
    org.hibernate.SQL: DEBUG # If show-sql is false but want to see SQL via logs
    org.hibernate.type.descriptor.sql: TRACE # To see bound parameters with SQL
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %X{traceId:-N/A} %X{spanId:-N/A} %X{orderId:-} %-5level %logger{36} - %msg%n"

# Resilience4j configuration (example, can be more detailed)
# resilience4j.circuitbreaker:
#   instances:
#     kafkaProducer:
#       registerHealthIndicator: true
#       slidingWindowSize: 10
#       failureRateThreshold: 50
#       waitDurationInOpenState: 10s
# resilience4j.retry:
#   instances:
#     outboxKafkaSender:
#       maxAttempts: 3
#       waitDuration: 1s
#       retryExceptions:
#         - org.springframework.kafka.KafkaException
#         - java.net.SocketTimeoutException
#       ignoreExceptions:
#         - org.apache.kafka.common.errors.SerializationException
---
