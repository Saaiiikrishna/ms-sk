apiVersion: autoscaling/v2 # Use v2 for richer metric support
kind: HorizontalPodAutoscaler
metadata:
  name: order-core-hpa
  namespace: default # Or your target namespace
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: order-core-deployment # Must match your Deployment name
  minReplicas: 2 # Start with at least 2 replicas for HA, can be 3 as per plan's Deployment
  maxReplicas: 5 # Max number of replicas
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75 # Target 75% CPU utilization
  # Example: Scaling based on Kafka consumer group lag (requires KEDA or Prometheus Adapter)
  # This example assumes metrics are exposed via Prometheus and a Prometheus Adapter is installed.
  # Or, use KEDA (Kafka-based Event-Driven Autoscaling) which is often preferred for Kafka lag.
  # ---
  # For KEDA, the HPA might be managed by KEDA's ScaledObject.
  # If using Prometheus Adapter for custom metrics:
  # - type: External # Or "Pods" if metric is per-pod
  #   external:
  #     metric:
  #       name: kafka_consumergroup_lag_sum # Name of the metric in Prometheus (sum over all partitions of a group)
  #       selector: # Labels to select the specific metric for this consumer group
  #         matchLabels:
  #           consumergroup: "order-core-group" # Match your consumer group
  #           topic: "order.api.created"        # Match a primary topic driving scaling
  #     target:
  #       type: AverageValue # Or Value
  #       averageValue: "100" # Target average lag of 100 messages per pod/instance
  # ---
  # Alternative for KEDA (Simplified - KEDA CRD `ScaledObject` would replace this HPA for Kafka lag)
  # If you still want a CPU-based HPA alongside KEDA, that's possible.
  # KEDA ScaledObject example (conceptual, not part of this HPA.yaml):
  # apiVersion: keda.sh/v1alpha1
  # kind: ScaledObject
  # metadata:
  #   name: order-core-keda-scaler
  #   namespace: default
  # spec:
  #   scaleTargetRef:
  #     name: order-core-deployment
  #   pollingInterval: 30
  #   cooldownPeriod:  300
  #   minReplicaCount: 2
  #   maxReplicaCount: 5
  #   triggers:
  #   - type: kafka
  #     metadata:
  #       bootstrapServers: "kafka-cluster-kafka-brokers.default.svc.cluster.local:9092"
  #       consumerGroup: "order-core-group"
  #       topic: "order.api.created" # Topic to monitor lag on
  #       lagThreshold: "50" # Number of messages lag to trigger scaling
  #       # Other KEDA specific configs like auth, offset reset policy etc.
  behavior: # Fine-tune scaling behavior (optional but recommended)
    scaleDown:
      stabilizationWindowSeconds: 300 # Default 300s
      policies:
      - type: Percent
        value: 100 # Allow scaling down all unneeded pods at once
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0 # Default 0s
      policies:
      - type: Percent
        value: 100 # Allow doubling the pod count
        periodSeconds: 60
      - type: Pods
        value: 2 # Or add a fixed number of pods, e.g., 2
        periodSeconds: 60
      selectPolicy: Max # Use the policy that allows the most scaling up
---
# Notes:
# - The Deployment `replicas` should ideally be <= `minReplicas` here or HPA will scale down initially.
#   The plan mentioned 3 replicas for Deployment, so minReplicas: 3 might be better. I'll use 2 for now as an example.
# - For Kafka lag-based scaling, KEDA is a common and robust solution. The HPA above shows a CPU metric
#   and comments out how one might approach Kafka lag with Prometheus Adapter.
#   If KEDA is used, it creates and manages its own HPA objects.
# - Ensure Kubernetes Metrics Server is installed for CPU/memory resource metrics.
# - Adjust `averageUtilization`, `minReplicas`, `maxReplicas` based on performance testing.
